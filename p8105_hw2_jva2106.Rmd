---
title: "Homework 2"
author: "Jyoti Ankam"
date: "September 28, 2018"
output: github_document
---

Loading the package - tidyverse:

```{r}

library(tidyverse)

```

Reading the csv dataset NYC transit:

Problem 1:
```{r}

nyc_transit = read_csv(file = "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line:entry, vending, ada) %>% 
  mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE))

```

The NYC transit dataset contains information about NYC Transit trains, stations and routes. Some of the relevant variables included - stations, trains, routes served, vending information and ada compliance information.
First we imported the data and clean the variables names by replacing spaces with underscores and making them lower case. Then, we selected the variables that were needed for analysis. We also changed the variable 'entry' to the logical type.

We have `r nrow(nyc_transit)` rows times `r ncol(nyc_transit)` columns. The data wasn't tidy at first as some of the data under routes was spread across multiple columns. In addition, data under route numbers was under the route variable (column).

```{r}

ada_compliant = distinct(nyc_transit, line, station_name, ada)

sum(ada_compliant$ada)

nrow(ada_compliant)
```

From the code chunk above and also from this inline code, we know that there are `r nrow(ada_compliant)` stations. From these `r nrow(ada_compliant)` stations, total `r sum(ada_compliant$ada)` are ada compliant.


```{r}

ent_vend_df = mutate(nyc_transit, vending = recode(vending, "YES" = TRUE, "NO" = FALSE),
                  entry_vend = !(entry == vending))

prop_vending = sum(ent_vend_df$entry_vend)/nrow(ent_vend_df)
  
```

In this code chunk above, we are identifying the stations with no vending but allow entrance. By using a logical variable, it seems easier to find the sum of logical variables to find the number of TRUEs, such that the logical condition is negated and the FALSES are converted to TRUEs.

We have `r sum(ent_vend_df$entry_vend)/nrow(ent_vend_df)` of entrance/exits with no vending that allow entrance.


Reformatting the data to find the total number of stations serving the A train service:

```{r}

reformat_df = gather(ent_vend_df, key = route_num, value = train, route1:route11) %>% 
  separate(route_num, into = c("delete", "route"), sep = 5) %>% 
  select(-delete) %>% 
  distinct(line, station_name, train, ada) %>% 
  filter(train == "A")

```

There are `r nrow(reformat_df)` distinct stations that serve the A train. From the distinct stations that serve the A train, `r sum(reformat_df$ada)` are ADA compliant.

Problem 2:

Reading Mr. Trash Wheel dataset and cleaning it:

```{r}

trash_wheel_df = readxl::read_excel("./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", sheet = "Mr. Trash Wheel", range = "A2:N258") %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster), dumpster != 23220) %>% 
  mutate(sports_balls = as.integer(sports_balls))

```

Reading and cleaning the precipitation datasets 2016 and 2017:

```{r}

precip_2016 = readxl::read_excel("./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", sheet = "2016 Precipitation", range = "A2:B14") %>% 
  janitor::clean_names() %>% 
  mutate(year = 2016) 


precip_2017 = readxl::read_excel("./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", sheet = "2017 Precipitation", range = "A2:B14") %>% 
  janitor::clean_names() %>% 
  mutate(year = 2017) %>% 
  filter(!is.na(total))

```

Combining the precipitation datasets of 2016 and 2017:

```{r}

precip_16_17_df = bind_rows(precip_2016, precip_2017)

## pulling months as a vector from the tibble in order to be able to apply the month.name function
month_vec = month.name[c(pull(precip_16_17_df, month))]

## coverting the vector into a tibble for binding the columns
month_name_df = tibble::as.tibble(month_vec)

## binding the columns together and renaming the variables
precip_total = bind_cols(precip_16_17_df, month_name_df) %>% 
  select(-month) %>% 
  select(year, month = value, total)

```

The median number of sportsballs in  a dumpster in 2016:

```{r}
median_balls_16 = trash_wheel_df %>% 
  filter(year == 2016)

```

The trash wheel dataset contains `r nrow(trash_wheel_df)` rows times `r ncol(trash_wheel_df)` columns after tidying/cleaning. It contains a wide range of information about the trashwheel waste collector. There's information about the different types of waste collected like number of sport balls, grocery bags, cigarette butts, chip bags, plastic and glass bottles etc. Information on date is also collected.


The precipitation datasets contain information about precipation for the years 2016 and 2017. There are `r nrow(precip_2016)` rows times `r ncol(precip_2016)` columns in the 2016 precipation dataset. In the 2017 dataset, there are `r nrow(precip_2017)` rows times `r ncol(precip_2017)` columns. Both datasets combined contain information on total precipation in each month.

The total precipitation in 2017 is `r sum(precip_2017$total)` and the median number of sports balls is `r median(median_balls_16$sports_balls)`.


Problem 3: Installing the package:

```{r}

# install.packages("devtools")
devtools::install_github("p8105/p8105.datasets")

library(p8105.datasets)

data(brfss_smart2010)
```

Tidying and formatting the data: focussing on the “Overall Health” topic and
excluding variables for class, topic, question, sample size, and everything from lower confidence limit to GeoLocation

```{r}

brfss_smart_df = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health") %>% 
  select(-(class:question), -sample_size, -(confidence_limit_low:geo_location)) %>% 
  spread(key = response, value = data_value) %>% 
  janitor::clean_names() %>% 
  mutate(excellent_verygood = excellent + very_good)
  
```

Using this dataset, answering the following:

There are `r nrow(distinct(brfss_smart_df, locationabbr))` distinct locations. Yes, all states are represented.

```{r}

observed_most = count(brfss_smart_df, locationabbr) %>% 
  top_n(1, n)

```

`r pull(observed_most, locationabbr)` is the most observed state with `r pull(observed_most, n)` municipalities/counties.


```{r}

data_2002_df = brfss_smart_df %>% 
  filter(year == 2002)

median(data_2002_df$excellent, na.rm = TRUE)

```

`r median(data_2002_df$excellent, na.rm = TRUE)` is the median of the Excellent response in 2002.


Histogram of Excellent responses in the year 2002:

```{r}

ggplot(data_2002_df, aes(x = excellent)) + 
  geom_histogram()

```

Scatterplot showing the proportion of “Excellent” response values in New York County and Queens County (both in NY State) in each year from 2002 to 2010:

```{r}

brfss_smart_df %>% 
  filter(locationdesc %in% c("NY - New York County", "NY - Queens County")) %>% 
  ggplot(aes(x = year, y = excellent, color = locationdesc)) +
  geom_point()

```

